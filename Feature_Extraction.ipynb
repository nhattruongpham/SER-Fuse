{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39767ece-68fc-4927-ac3a-177d7aa4f4a8",
   "metadata": {},
   "source": [
    "# I. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9aa141-5bc7-46bb-97ef-4cb707e9a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import torch\n",
    "import torchaudio\n",
    "import pickle\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba84e50-b569-4a66-a478-af528b513a93",
   "metadata": {},
   "source": [
    "# II. Define metadata paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad9ed3-467d-41fa-9f9a-2f9eb4fc8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECES dataset paths\n",
    "ECES_TRAIN_PATH = \"metadata/ECES_metadata_train.csv\"\n",
    "ECES_VAL_PATH = \"metadata/ECES_metadata_val.csv\"\n",
    "ECES_TEST_PATH = \"metadata/ECES_metadata_test.csv\"\n",
    "# IEMOCAP dataset paths\n",
    "IEMOCAP_TRAIN_PATH = \"metadata/IEMOCAP_metadata_train.csv\"\n",
    "IEMOCAP_VAL_PATH = \"metadata/IEMOCAP_metadata_val.csv\"\n",
    "IEMOCAP_TEST_PATH = \"metadata/IEMOCAP_metadata_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc9a85-a5a5-4eba-af55-6abe527bd8df",
   "metadata": {},
   "source": [
    "# III. ECAPA for audio embeddings + BERT for text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b0aa9-7b9e-464a-9595-fea842c71a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_eng = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text_model_eng = BertModel.from_pretrained('bert-base-uncased')\n",
    "text_model_eng.to(device)\n",
    "tokenizer_cmn = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "text_model_cmn = BertModel.from_pretrained('bert-base-chinese')\n",
    "text_model_cmn.to(device)\n",
    "TEXT_MAX_LENGTH = 100\n",
    "audio_model = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
    "print(\"All loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1b372-0197-4d5b-8cce-b4d0053dbec9",
   "metadata": {},
   "source": [
    "## 1. ECES ENG-CMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84244b1-55d5-4d78-a5c7-528b5a5350a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set for ECES ENG-CMN\n",
    "train_list = pd.read_csv(ECES_TRAIN_PATH)\n",
    "train_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(train_list)):\n",
    "        text = train_list['raw_text'][idx]\n",
    "        if train_list['language'][idx] == \"eng\":\n",
    "            text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_eng(**text_token)\n",
    "        elif train_list['language'][idx] == \"cmn\":\n",
    "            text_token = tokenizer_cmn(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_cmn(**text_token)\n",
    "        text_embeddings = text_outputs.last_hidden_state\n",
    "        text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "        audio_file = train_list['audio_file'][idx]\n",
    "        audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "        audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "        audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "        label = train_list['label'][idx]\n",
    "        label = torch.tensor(label)\n",
    "        train_pkl.append({\n",
    "            'text_embed': text_embed,\n",
    "            'audio_embed': audio_embed,\n",
    "            'label': label\n",
    "        })\n",
    "train_file = open(\"features/ECESD_ENG_CMN_BERT_ECAPA_train.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(train_pkl, train_file)\n",
    "\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e17665-053b-4b0b-bb94-dba665a24fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set for ECES ENG-CMN\n",
    "val_list = pd.read_csv(ECES_VAL_PATH)\n",
    "val_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(val_list)):\n",
    "        text = val_list['raw_text'][idx]\n",
    "        if val_list['language'][idx] == \"eng\":\n",
    "            text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_eng(**text_token)\n",
    "        elif val_list['language'][idx] == \"cmn\":\n",
    "            text_token = tokenizer_cmn(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_cmn(**text_token)\n",
    "        text_embeddings = text_outputs.last_hidden_state\n",
    "        text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "        audio_file = val_list['audio_file'][idx]\n",
    "        audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "        audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "        audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "        label = val_list['label'][idx]\n",
    "        label = torch.tensor(label)\n",
    "        val_pkl.append({\n",
    "            'text_embed': text_embed,\n",
    "            'audio_embed': audio_embed,\n",
    "            'label': label\n",
    "        })\n",
    "val_file = open(\"features/ECESD_ENG_CMN_BERT_ECAPA_val.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(val_pkl, val_file)\n",
    "\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435759ed-5e39-4578-a82b-9633f440d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create independent testing set for ECES ENG-CMN\n",
    "test_list = pd.read_csv(ECES_TEST_PATH)\n",
    "test_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_list)):\n",
    "        text = test_list['raw_text'][idx]\n",
    "        if test_list['language'][idx] == \"eng\":\n",
    "            text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_eng(**text_token)\n",
    "        elif test_list['language'][idx] == \"cmn\":\n",
    "            text_token = tokenizer_cmn(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_cmn(**text_token)\n",
    "        text_embeddings = text_outputs.last_hidden_state\n",
    "        text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "        audio_file = test_list['audio_file'][idx]\n",
    "        audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "        audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "        audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "        label = test_list['label'][idx]\n",
    "        label = torch.tensor(label)\n",
    "        test_pkl.append({\n",
    "            'text_embed': text_embed,\n",
    "            'audio_embed': audio_embed,\n",
    "            'label': label\n",
    "        })\n",
    "test_file = open(\"features/ECESD_ENG_CMN_BERT_ECAPA_test.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(test_pkl, test_file)\n",
    "\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd57ed-0520-4d5e-8a78-2bee5dca6d65",
   "metadata": {},
   "source": [
    "## 2. ECES CMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59951386-b7d6-49aa-bbac-ba1f7d4efaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set for ECES CMN\n",
    "train_list = pd.read_csv(ECES_TRAIN_PATH)\n",
    "train_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(train_list)):\n",
    "        text = train_list['raw_text'][idx]\n",
    "        if train_list['language'][idx] == \"cmn\":\n",
    "            text_token = tokenizer_cmn(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_cmn(**text_token)\n",
    "            text_embeddings = text_outputs.last_hidden_state\n",
    "            text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "            audio_file = train_list['audio_file'][idx]\n",
    "            audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "            audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "            audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "            label = train_list['label'][idx]\n",
    "            label = torch.tensor(label)\n",
    "            train_pkl.append({\n",
    "                'text_embed': text_embed,\n",
    "                'audio_embed': audio_embed,\n",
    "                'label': label\n",
    "            })\n",
    "train_file = open(\"features/ECESD_CMN_BERT_ECAPA_train.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(train_pkl, train_file)\n",
    "\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759fb6b-4322-43c6-abe2-97ac5ed23db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set for ECES CMN\n",
    "val_list = pd.read_csv(ECES_VAL_PATH)\n",
    "val_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(val_list)):\n",
    "        text = val_list['raw_text'][idx]\n",
    "        if val_list['language'][idx] == \"cmn\":\n",
    "            text_token = tokenizer_cmn(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_cmn(**text_token)\n",
    "            text_embeddings = text_outputs.last_hidden_state\n",
    "            text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "            audio_file = val_list['audio_file'][idx]\n",
    "            audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "            audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "            audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "            label = val_list['label'][idx]\n",
    "            label = torch.tensor(label)\n",
    "            val_pkl.append({\n",
    "                'text_embed': text_embed,\n",
    "                'audio_embed': audio_embed,\n",
    "                'label': label\n",
    "            })\n",
    "val_file = open(\"features/ECESD_CMN_BERT_ECAPA_val.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(val_pkl, val_file)\n",
    "\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f131b37-2b72-4279-9301-10bdc038a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create independent testing set for ECES CMN\n",
    "test_list = pd.read_csv(ECES_TEST_PATH)\n",
    "test_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_list)):\n",
    "        text = test_list['raw_text'][idx]\n",
    "        if test_list['language'][idx] == \"cmn\":\n",
    "            text_token = tokenizer_cmn(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_cmn(**text_token)\n",
    "            text_embeddings = text_outputs.last_hidden_state\n",
    "            text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "            audio_file = test_list['audio_file'][idx]\n",
    "            audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "            audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "            audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "            label = test_list['label'][idx]\n",
    "            label = torch.tensor(label)\n",
    "            test_pkl.append({\n",
    "                'text_embed': text_embed,\n",
    "                'audio_embed': audio_embed,\n",
    "                'label': label\n",
    "            })\n",
    "test_file = open(\"features/ECESD_CMN_BERT_ECAPA_test.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(test_pkl, test_file)\n",
    "\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2876fd2-e73a-411a-9596-456bd973e6df",
   "metadata": {},
   "source": [
    "## 3. ECES ENG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d3939-72f9-4d69-a2d4-dcaaed8242cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set for ECES ENG\n",
    "train_list = pd.read_csv(ECES_TRAIN_PATH)\n",
    "train_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(train_list)):\n",
    "        text = train_list['raw_text'][idx]\n",
    "        if train_list['language'][idx] == \"eng\":\n",
    "            text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_eng(**text_token)\n",
    "            text_embeddings = text_outputs.last_hidden_state\n",
    "            text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "            audio_file = train_list['audio_file'][idx]\n",
    "            audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "            audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "            audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "            label = train_list['label'][idx]\n",
    "            label = torch.tensor(label)\n",
    "            train_pkl.append({\n",
    "                'text_embed': text_embed,\n",
    "                'audio_embed': audio_embed,\n",
    "                'label': label\n",
    "            })\n",
    "train_file = open(\"features/ECESD_ENG_BERT_ECAPA_train.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(train_pkl, train_file)\n",
    "\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb3b50-e773-4ace-b781-65574281f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set for ECES ENG\n",
    "val_list = pd.read_csv(ECES_VAL_PATH)\n",
    "val_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(val_list)):\n",
    "        text = val_list['raw_text'][idx]\n",
    "        if val_list['language'][idx] == \"eng\":\n",
    "            text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_eng(**text_token)\n",
    "            text_embeddings = text_outputs.last_hidden_state\n",
    "            text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "            audio_file = val_list['audio_file'][idx]\n",
    "            audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "            audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "            audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "            label = val_list['label'][idx]\n",
    "            label = torch.tensor(label)\n",
    "            val_pkl.append({\n",
    "                'text_embed': text_embed,\n",
    "                'audio_embed': audio_embed,\n",
    "                'label': label\n",
    "            })\n",
    "val_file = open(\"features/ECESD_ENG_BERT_ECAPA_val.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(val_pkl, val_file)\n",
    "\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff393f6-d855-467c-b702-69f54f1b631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create independent testing set for ECES ENG\n",
    "test_list = pd.read_csv(ECES_TEST_PATH)\n",
    "test_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_list)):\n",
    "        text = test_list['raw_text'][idx]\n",
    "        if test_list['language'][idx] == \"eng\":\n",
    "            text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "            text_token = text_token.to(device)\n",
    "            text_outputs = text_model_eng(**text_token)\n",
    "            text_embeddings = text_outputs.last_hidden_state\n",
    "            text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "            audio_file = test_list['audio_file'][idx]\n",
    "            audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "            audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "            audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "            label = test_list['label'][idx]\n",
    "            label = torch.tensor(label)\n",
    "            test_pkl.append({\n",
    "                'text_embed': text_embed,\n",
    "                'audio_embed': audio_embed,\n",
    "                'label': label\n",
    "            })\n",
    "test_file = open(\"features/ECESD_ENG_BERT_ECAPA_test.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(test_pkl, test_file)\n",
    "\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e9bf7-bd82-4912-a6e1-51e69baf28f1",
   "metadata": {},
   "source": [
    "## 4. IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198492a4-3d90-4a4b-a0be-9e4d6d667482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set for IEMOCAP\n",
    "train_list = pd.read_csv(IEMOCAP_TRAIN_PATH)\n",
    "train_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(train_list)):\n",
    "        text = train_list['raw_text'][idx]\n",
    "        text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "        text_token = text_token.to(device)\n",
    "        text_outputs = text_model_eng(**text_token)\n",
    "        text_embeddings = text_outputs.last_hidden_state\n",
    "        text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "        audio_file = train_list['audio_file'][idx]\n",
    "        audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "        audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "        audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "        label = train_list['label'][idx]\n",
    "        label = torch.tensor(label)\n",
    "        train_pkl.append({\n",
    "            'text_embed': text_embed,\n",
    "            'audio_embed': audio_embed,\n",
    "            'label': label\n",
    "        })\n",
    "train_file = open(\"features/IEMOCAP_BERT_ECAPA_train.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(train_pkl, train_file)\n",
    "\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0082f-33e0-4187-926e-313858d86a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set for IEMOCAP\n",
    "val_list = pd.read_csv(IEMOCAP_VAL_PATH)\n",
    "val_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(val_list)):\n",
    "        text = val_list['raw_text'][idx]\n",
    "        text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "        text_token = text_token.to(device)\n",
    "        text_outputs = text_model_eng(**text_token)\n",
    "        text_embeddings = text_outputs.last_hidden_state\n",
    "        text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "        audio_file = val_list['audio_file'][idx]\n",
    "        audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "        audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "        audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "        label = val_list['label'][idx]\n",
    "        label = torch.tensor(label)\n",
    "        val_pkl.append({\n",
    "            'text_embed': text_embed,\n",
    "            'audio_embed': audio_embed,\n",
    "            'label': label\n",
    "        })\n",
    "val_file = open(\"features/IEMOCAP_BERT_ECAPA_val.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(val_pkl, val_file)\n",
    "\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f18f1-d13e-457d-aaa4-6ec3a6ee6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create independent testing set for IEMOCAP\n",
    "test_list = pd.read_csv(IEMOCAP_TEST_PATH)\n",
    "test_pkl = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_list)):\n",
    "        text = test_list['raw_text'][idx]\n",
    "        text_token = tokenizer_eng(text, return_tensors=\"pt\")\n",
    "        text_token = text_token.to(device)\n",
    "        text_outputs = text_model_eng(**text_token)\n",
    "        text_embeddings = text_outputs.last_hidden_state\n",
    "        text_embed = text_embeddings[:, 0, :][0].cpu()\n",
    "        audio_file = test_list['audio_file'][idx]\n",
    "        audio_signal, _ = torchaudio.load(audio_file, normalize=True)\n",
    "        audio_outputs = audio_model.encode_batch(audio_signal)\n",
    "        audio_embed = audio_outputs.mean(axis=0)[0]\n",
    "        label = test_list['label'][idx]\n",
    "        label = torch.tensor(label)\n",
    "        test_pkl.append({\n",
    "            'text_embed': text_embed,\n",
    "            'audio_embed': audio_embed,\n",
    "            'label': label\n",
    "        })\n",
    "test_file = open(\"features/IEMOCAP_BERT_ECAPA_test.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(test_pkl, test_file)\n",
    "\n",
    "test_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
