{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49fba3-4519-4c71-975f-c752cc3f55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d267857-b349-43fd-b702-244eba509811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customized_Dataset(Dataset):\n",
    "    def __init__(self, metadata):\n",
    "        super(Customized_Dataset, self).__init__()\n",
    "        self.data = pickle.load(open(metadata, 'rb'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with torch.no_grad():\n",
    "            text_embed = self.data[idx]['text_embed']\n",
    "            audio_embed = self.data[idx]['audio_embed']\n",
    "            label = self.data[idx]['label']\n",
    "\n",
    "        return text_embed, audio_embed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa54a40-fa02-4445-b531-f193c24f44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_metadata = \"features/ECESD_ENG_CMN_BERT_ECAPA_train.pkl\"\n",
    "val_metadata = \"features/ECESD_ENG_CMN_BERT_ECAPA_val.pkl\"\n",
    "train_dataset = Customized_Dataset(train_metadata)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataset = Customized_Dataset(val_metadata)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbe1f5-af47-4098-80e7-2f7bf13d2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Multi-modal model\n",
    "class MMSER(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(MMSER, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = nn.Dropout(.2)\n",
    "        self.linear1 = nn.Linear(960, 256)\n",
    "        self.linear2 = nn.Linear(256, 64)\n",
    "        self.linear3 = nn.Linear(64, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, text_embed, audio_embed):\n",
    "        concat_embed=torch.cat((text_embed,audio_embed), dim=1)\n",
    "        x = self.dropout(concat_embed)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        y_logits = self.linear3(x)\n",
    "        y_softmax = self.softmax(y_logits)\n",
    "        return y_logits, y_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9430654-6a0f-4658-914c-4a345b6a34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa8c74-132f-4911-841a-38d16a8594d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "    class_weights = {cls: 1.0/count for cls, count in Counter(y_true).items()}\n",
    "    wa = balanced_accuracy_score(y_true, y_pred, sample_weight=[class_weights[cls] for cls in y_true])\n",
    "    ua = accuracy_score(y_true, y_pred)\n",
    "    return wa, ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4c218-bbc2-4683-98f7-87de37a9afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, optim, loss_fn, accuracy_fn):\n",
    "    train_loss = 0.0\n",
    "    train_wa = 0.0\n",
    "    train_ua = 0.0\n",
    "    y_true_ls = []\n",
    "    y_pred_ls = []\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (text_embed, audio_embed, label) in enumerate(dataloader):\n",
    "        text_embed = text_embed.to(device)\n",
    "        audio_embed = audio_embed.to(device)\n",
    "        label = label.to(device)\n",
    "        output_logits, output_softmax = model(text_embed, audio_embed)\n",
    "        output_logits, output_softmax = output_logits.to(device), output_softmax.to(device)\n",
    "        y_preds = output_softmax.argmax(dim=1).to(device)\n",
    "        \n",
    "        wa, ua = calculate_accuracy(y_preds.cpu().numpy(), label.cpu().numpy())\n",
    "        y_true_ls.append(label.cpu().numpy())\n",
    "        y_pred_ls.append(y_preds.cpu().numpy())\n",
    "        loss = loss_fn(output_logits, label)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_wa += wa\n",
    "        train_ua += ua\n",
    "        \n",
    "        # if batch % 20 == 0:\n",
    "        #     print(f\"\\tBatch {batch}: Train loss: {loss:.5f} | Train WA : {wa:.4f} | Train UA : {ua:.4f}\")\n",
    "        #     print(\"----------------------------------------\")\n",
    "        \n",
    "    train_loss /= len(dataloader)\n",
    "    train_wa /= len(dataloader)\n",
    "    train_ua /= len(dataloader)\n",
    "    print(f\"Total Train loss: {train_loss:.5f} | Total Train WA : {wa:.4f} | Total Train UA : {ua:.4f}\")\n",
    "    \n",
    "    return train_loss, train_wa, train_ua, y_true_ls, y_pred_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e3515-668b-4b15-a1c8-b9df9e1b05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model, dataloader, loss_fn, accuracy_fn):\n",
    "    eval_loss = 0.0\n",
    "    eval_wa = 0.0\n",
    "    eval_ua = 0.0\n",
    "    y_true_ls = []\n",
    "    y_pred_ls = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (text_embed, audio_embed, label) in enumerate(dataloader):\n",
    "            text_embed = text_embed.to(device)\n",
    "            audio_embed = audio_embed.to(device)\n",
    "            label = label.to(device)\n",
    "            output_logits, output_softmax = model(text_embed, audio_embed)\n",
    "            output_logits, output_softmax = output_logits.to(device), output_softmax.to(device)\n",
    "            y_preds = output_softmax.argmax(dim=1).to(device)\n",
    "            \n",
    "            wa, ua = calculate_accuracy(y_preds.cpu().numpy(), label.cpu().numpy())\n",
    "            y_true_ls.append(label.cpu().numpy())\n",
    "            y_pred_ls.append(y_preds.cpu().numpy())\n",
    "            loss = loss_fn(output_logits, label)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            eval_wa += wa\n",
    "            eval_ua += ua\n",
    "\n",
    "            # if batch % 20 == 0:\n",
    "            #     print(f\"\\tBatch {batch}: Test loss: {loss:.5f} | Test WA : {wa:.4f} | Test UA : {ua:.4f}\")\n",
    "            #     print(\"----------------------------------------\")\n",
    "        \n",
    "        eval_loss /= len(dataloader)\n",
    "        eval_wa /= len(dataloader)\n",
    "        eval_ua /= len(dataloader)\n",
    "        print(f\"Total Test loss: {eval_loss:.5f} | Total Test WA: {eval_wa:.4f} | Total Test UA: {eval_ua:4f}\")\n",
    "        \n",
    "        return eval_loss, eval_wa, eval_ua, y_true_ls, y_pred_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44875d-df57-4117-9a5f-47c51b2a67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_loss_hist, train_wa_hist, train_ua_hist, val_loss_hist, val_wa_hist, val_ua_hist = [], [], [], [], [], []\n",
    "\n",
    "best_w = {}\n",
    "\n",
    "best_train_loss, best_val_loss = 10000, 10000\n",
    "best_wa, best_ua = 0.0, 0.0\n",
    "\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "model=MMSER(num_classes=4)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e1688-311e-48a9-9e0c-9d1f7dcbc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multi-modal model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Epoch\", epoch)\n",
    "    train_loss, train_wa, train_ua, y_true_ls, y_pred_ls = train_step(model, train_dataloader, optimizer, criterion, calculate_accuracy)\n",
    "    val_loss, val_wa, val_ua, y_true_ls, y_pred_ls = eval_step(model, val_dataloader, criterion, calculate_accuracy)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    epochs.append(epoch)\n",
    "    train_loss_hist.append(train_loss)\n",
    "    val_loss_hist.append(val_loss)\n",
    "    train_wa_hist.append(train_wa*100)\n",
    "    val_wa_hist.append(val_wa*100)\n",
    "    train_ua_hist.append(train_ua*100)\n",
    "    val_ua_hist.append(val_ua*100)\n",
    "    \n",
    "    if train_loss < best_train_loss and val_loss < best_val_loss:\n",
    "        best_train_loss, best_val_loss = train_loss, val_loss\n",
    "        best_wa, best_ua = val_wa, val_ua\n",
    "        torch.save(model.state_dict(), \"saved_models/ECESD_ENG_CMN_BERT_ECAPA.pt\")\n",
    "        best_w = model.state_dict()\n",
    "    \n",
    "    print(\"\\n==============================\\n\")\n",
    "print(\"Best WA: \", best_wa)\n",
    "print(\"Best UA: \", best_ua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeccaa5-1128-432c-9ca1-e5bdf739931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = len(epochs)\n",
    "\n",
    "plt.plot(epochs, train_loss_hist, color='r', label='Train Loss')\n",
    "plt.plot(epochs, val_loss_hist, color='g', label='Eval. Loss')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(f\"Train and Eval. Loss along {epoch} epochs\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd3346-2199-455e-be17-8649522737ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_wa_hist, color='r', label='Train BACC')\n",
    "plt.plot(epochs, val_wa_hist, color='g', label='Eval. BACC')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"BACC Value\")\n",
    "plt.title(f\"Train and Eval. Accuracy along {epoch} epochs\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
