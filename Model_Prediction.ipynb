{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2622f-a63d-416f-b497-194351cd370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0505b49-8121-4087-977c-6a9275606816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "    class_weights = {cls: 1.0/count for cls, count in Counter(y_true).items()}\n",
    "    wa = balanced_accuracy_score(y_true, y_pred, sample_weight=[class_weights[cls] for cls in y_true])\n",
    "    ua = accuracy_score(y_true, y_pred)\n",
    "    return wa, ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df973c5-c2f1-4b5f-8fcf-4745d9d28e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, dataloader, accuracy_fn):\n",
    "    eval_wa = 0.0\n",
    "    eval_ua = 0.0\n",
    "    y_true_ls = []\n",
    "    y_pred_ls = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (text_embed, audio_embed, label) in enumerate(dataloader):\n",
    "            text_embed = text_embed.to(device)\n",
    "            audio_embed = audio_embed.to(device)\n",
    "            label = label.to(device)\n",
    "            output_logits, output_softmax = model(text_embed, audio_embed)\n",
    "            output_logits, output_softmax = output_logits.to(device), output_softmax.to(device)\n",
    "            y_preds = output_softmax.argmax(dim=1).to(device)\n",
    "            \n",
    "            wa, ua = calculate_accuracy(y_preds.cpu().numpy(), label.cpu().numpy())\n",
    "            y_true_ls.append(label.cpu().numpy())\n",
    "            y_pred_ls.append(y_preds.cpu().numpy())\n",
    "\n",
    "            eval_wa += wa\n",
    "            eval_ua += ua\n",
    "\n",
    "            # if batch % 20 == 0:\n",
    "            #     print(f\"\\tBatch {batch}: Test loss: {loss:.5f} | Test WA : {wa:.4f} | Test UA : {ua:.4f}\")\n",
    "            #     print(\"----------------------------------------\")\n",
    "        \n",
    "        eval_wa /= len(dataloader)\n",
    "        eval_ua /= len(dataloader)\n",
    "        print(f\"Total Test WA: {eval_wa:.4f} | Total Test UA: {eval_ua:4f}\")\n",
    "        \n",
    "        return eval_wa, eval_ua, y_true_ls, y_pred_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed73600-bacf-4922-841d-05a542eebe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "test_metadata = \"features/ECESD_ENG_CMN_BERT_ECAPA_test.pkl\"\n",
    "test_dataset = Customized_Dataset(test_metadata)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13975fe8-41c8-4b51-b6d4-5ff88d9a4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customized_Dataset(Dataset):\n",
    "    def __init__(self, metadata):\n",
    "        super(Customized_Dataset, self).__init__()\n",
    "        self.data = pickle.load(open(metadata, 'rb'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with torch.no_grad():\n",
    "            text_embed = self.data[idx]['text_embed']\n",
    "            audio_embed = self.data[idx]['audio_embed']\n",
    "            label = self.data[idx]['label']\n",
    "\n",
    "        return text_embed, audio_embed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6beecfb-e79b-4c5e-8654-1644d16994aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Multi-modal model\n",
    "class MMSER(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(MMSER, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = nn.Dropout(.2)\n",
    "        self.linear1 = nn.Linear(960, 256)\n",
    "        self.linear2 = nn.Linear(256, 64)\n",
    "        self.linear3 = nn.Linear(64, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, text_embed, audio_embed):\n",
    "        concat_embed=torch.cat((text_embed,audio_embed), dim=1)\n",
    "        x = self.dropout(concat_embed)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        y_logits = self.linear3(x)\n",
    "        y_softmax = self.softmax(y_logits)\n",
    "        return y_logits, y_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a96a4-7974-4592-a411-df25c64b90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = MMSER(num_classes=4)\n",
    "loaded_model.load_state_dict(torch.load(\"saved_models/ECESD_ENG_CMN_BERT_ECAPA.pt\"))\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514bb60-80a6-4bd4-8184-5698454b2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "eces_test_wa, eces_test_ua, y_true_ls, y_pred_ls = model_prediction(loaded_model, test_dataloader, calculate_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b38dc8-0a45-4ced-bba5-f83f0b44ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_ls = np.concatenate(y_true_ls, axis=0)\n",
    "y_pred_ls = np.concatenate(y_pred_ls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36a446-5b7c-4507-b796-884982004c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.array(y_true_ls), np.array(y_pred_ls))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be9706-f564-4a46-8ec1-f6af74b0ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmn = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "\n",
    "ax = plt.subplots(figsize=(8, 5.5))[1]\n",
    "sns.heatmap(cmn, cmap='flare', annot=True, square=True, linecolor='black', linewidths=0.75, ax = ax, fmt = '.2f', annot_kws={'size': 16})\n",
    "ax.set_xlabel('Predicted', fontsize=18, fontweight='bold')\n",
    "ax.xaxis.set_label_position('bottom')\n",
    "ax.xaxis.set_ticklabels([\"Anger\", \"Happiness\", \"Neutral\", \"Sadness\"], fontsize=16)\n",
    "ax.set_ylabel('Ground Truth', fontsize=18, fontweight='bold')\n",
    "ax.yaxis.set_ticklabels([\"Anger\", \"Happiness\", \"Neutral\", \"Sadness\"], fontsize=16)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.savefig(\"Confusion_Matrices/ECESD_ENG_CMN_BERT_ECAPA.pdf\", dpi=600, bbox_inches='tight') # Uncomment to save figures\n",
    "# plt.savefig(\"Confusion_Matrices/ECESD_ENG_CMN_BERT_ECAPA.png\", dpi=600, bbox_inches='tight') # Uncomment to save figures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
